# -*- coding: utf-8 -*-
"""Resnet_Transfer_Learning_Cats/Dogs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LGhnU573zdMSxT946Bg_8-YMtmzOJZ36
"""

from keras.applications.resnet50 import ResNet50
import os
import shutil
import numpy as np
from keras.preprocessing.image import ImageDataGenerator

model = ResNet50(weights='imagenet',
                    include_top=False,input_shape = (224, 224, 3))

model.summary()

!wget --no-check-certificate \
    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
    -O /tmp/cats_and_dogs_filtered.zip

import os
import zipfile

local_zip = '/tmp/cats_and_dogs_filtered.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

base_dir = '/tmp/cats_and_dogs_filtered'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Directory with our training cat pictures
train_cats_dir = os.path.join(train_dir, 'cats')

# Directory with our training dog pictures
train_dogs_dir = os.path.join(train_dir, 'dogs')

# Directory with our validation cat pictures
validation_cats_dir = os.path.join(validation_dir, 'cats')

# Directory with our validation dog pictures
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

train_cat_fnames = os.listdir(train_cats_dir)
print (train_cat_fnames[:10])

train_dog_fnames = os.listdir(train_dogs_dir)
train_dog_fnames.sort()
print (train_dog_fnames[:10])

print ('total training cat images:', len(os.listdir(train_cats_dir)) )
print ('total training dog images:', len(os.listdir(train_dogs_dir)))
print ('total validation cat images:', len(os.listdir(validation_cats_dir)))
print ('total validation dog images:', len(os.listdir(validation_dogs_dir)))

# %matplotlib inline

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Parameters for our graph; we'll output images in a 4x4 configuration
nrows = 4
ncols = 4

# Index for iterating over images
pic_index = 0

# Set up matplotlib fig, and size it to fit 4x4 pics
fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 4)

pic_index += 8
next_cat_pix = [os.path.join(train_cats_dir, fname) 
                for fname in train_cat_fnames[pic_index-8:pic_index]]
next_dog_pix = [os.path.join(train_dogs_dir, fname) 
                for fname in train_dog_fnames[pic_index-8:pic_index]]

for i, img_path in enumerate(next_cat_pix+next_dog_pix):
  # Set up subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # Don't show axes (or gridlines)

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        shuffle=True
        )

validation_generator = train_datagen.flow_from_directory(
        validation_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        shuffle=True
        )

for layer in model.layers:
   layer.trainable = False

from keras import optimizers
from keras.models import Sequential, Model 
from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D
from keras import backend as k 
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping

#Adding custom Layers 
x = model.output
x = Flatten()(x)
x = Dense(8, activation="relu")(x)
x = Dropout(0.6)(x)
predictions = Dense(1, activation="sigmoid")(x)

model_final = Model(inputs = model.input, outputs = predictions)

model_final.compile(loss = "binary_crossentropy", optimizer = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True), metrics=["accuracy"])

model_final.summary()

from google.colab import files
# checkpoint
filepath="weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

model_final.fit_generator(
train_generator,
steps_per_epoch = 1000/32,
epochs = 20,
validation_data = validation_generator,
validation_steps = 500/32,
callbacks=callbacks_list
  )

model_final.load_weights('weights-improvement-01-0.49.hdf5')

import  keras.preprocessing.image as image
img1=image.load_img(train_cats_dir+'/'+train_cat_fnames[0],target_size=(224, 224))
img1=img1.resize((224,224))
x = image.img_to_array(img1)
x = np.expand_dims(x, axis=0)
print(x.shape)
y_proba=model_final.predict(x)
print(y_proba.argmax(axis=-1))
label_map = (train_generator.class_indices)
print(label_map)